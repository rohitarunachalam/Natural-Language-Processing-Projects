{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this project, I will attempt to solve the following problem. Given a headline, predict whether or not it is from the Onion (a satire news source). I wil first attempt to do this using a Nueral Bag Of Words (NBOW model). Then, I'll attempt to use a LSTM and hopefully get better results."
      ],
      "metadata": {
        "id": "maRLUA9Jsjca"
      },
      "id": "maRLUA9Jsjca"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRdPqeMMFEIY"
      },
      "source": [
        "### Part 1. Loading and Preprocessing Data \n",
        "The following cell loads the OnionOrNot dataset"
      ],
      "id": "ZRdPqeMMFEIY"
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://raw.githubusercontent.com/lukefeilberg/onion/master/OnionOrNot.csv > OnionOrNot.csv"
      ],
      "metadata": {
        "id": "YmV_uknBJA-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8ca6e47-7ede-42a2-a41c-31d95a4d474c"
      },
      "id": "YmV_uknBJA-o",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 1903k  100 1903k    0     0  9019k      0 --:--:-- --:--:-- --:--:-- 9019k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3DkMDu7FEIZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "id": "L3DkMDu7FEIZ"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import html\n",
        "\n",
        "def spec_add_spaces(t: str) -> str:\n",
        "    \"Add spaces around / and # in `t`. \\n\"\n",
        "    return re.sub(r\"([/#\\n])\", r\" \\1 \", t)\n",
        "\n",
        "def rm_useless_spaces(t: str) -> str:\n",
        "    \"Remove multiple spaces in `t`.\"\n",
        "    return re.sub(\" {2,}\", \" \", t)\n",
        "\n",
        "def replace_multi_newline(t: str) -> str:\n",
        "    return re.sub(r\"(\\n(\\s)*){2,}\", \"\\n\", t)\n",
        "\n",
        "def fix_html(x: str) -> str:\n",
        "    \"List of replacements from html strings in `x`.\"\n",
        "    re1 = re.compile(r\"  +\")\n",
        "    x = (\n",
        "        x.replace(\"#39;\", \"'\")\n",
        "        .replace(\"amp;\", \"&\")\n",
        "        .replace(\"#146;\", \"'\")\n",
        "        .replace(\"nbsp;\", \" \")\n",
        "        .replace(\"#36;\", \"$\")\n",
        "        .replace(\"\\\\n\", \"\\n\")\n",
        "        .replace(\"quot;\", \"'\")\n",
        "        .replace(\"<br />\", \"\\n\")\n",
        "        .replace('\\\\\"', '\"')\n",
        "        .replace(\" @.@ \", \".\")\n",
        "        .replace(\" @-@ \", \"-\")\n",
        "        .replace(\" @,@ \", \",\")\n",
        "        .replace(\"\\\\\", \" \\\\ \")\n",
        "    )\n",
        "    return re1.sub(\" \", html.unescape(x))\n",
        "\n",
        "def clean_text(input_text):\n",
        "    text = fix_html(input_text)\n",
        "    text = replace_multi_newline(text)\n",
        "    text = spec_add_spaces(text)\n",
        "    text = rm_useless_spaces(text)\n",
        "    text = text.strip()\n",
        "    return text"
      ],
      "metadata": {
        "id": "ctNnE1Ui8oKw"
      },
      "id": "ctNnE1Ui8oKw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqtdrhF8FEIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2603a7d3-d2d0-44e7-e1e4-74e9f9c5a23a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "\n",
        "nltk.download('punkt')\n",
        "df              = pd.read_csv(\"OnionOrNot.csv\")\n",
        "df[\"tokenized\"] = df[\"text\"].apply(lambda x: nltk.word_tokenize(clean_text(x.lower())))"
      ],
      "id": "vqtdrhF8FEIZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJjScqV3FEIb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "78313af7-f337-4ca8-cfb2-2a88696ad2d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label  \\\n",
              "0  Entire Facebook Staff Laughs As Man Tightens P...      1   \n",
              "1  Muslim Woman Denied Soda Can for Fear She Coul...      0   \n",
              "2  Bold Move: Hulu Has Announced That They’re Gon...      1   \n",
              "3  Despondent Jeff Bezos Realizes He’ll Have To W...      1   \n",
              "4  For men looking for great single women, online...      1   \n",
              "\n",
              "                                           tokenized  \n",
              "0  [entire, facebook, staff, laughs, as, man, tig...  \n",
              "1  [muslim, woman, denied, soda, can, for, fear, ...  \n",
              "2  [bold, move, :, hulu, has, announced, that, th...  \n",
              "3  [despondent, jeff, bezos, realizes, he, ’, ll,...  \n",
              "4  [for, men, looking, for, great, single, women,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-482789d0-9e6a-403a-94d3-a50eab4ff82a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Entire Facebook Staff Laughs As Man Tightens P...</td>\n",
              "      <td>1</td>\n",
              "      <td>[entire, facebook, staff, laughs, as, man, tig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Muslim Woman Denied Soda Can for Fear She Coul...</td>\n",
              "      <td>0</td>\n",
              "      <td>[muslim, woman, denied, soda, can, for, fear, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bold Move: Hulu Has Announced That They’re Gon...</td>\n",
              "      <td>1</td>\n",
              "      <td>[bold, move, :, hulu, has, announced, that, th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Despondent Jeff Bezos Realizes He’ll Have To W...</td>\n",
              "      <td>1</td>\n",
              "      <td>[despondent, jeff, bezos, realizes, he, ’, ll,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>For men looking for great single women, online...</td>\n",
              "      <td>1</td>\n",
              "      <td>[for, men, looking, for, great, single, women,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-482789d0-9e6a-403a-94d3-a50eab4ff82a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-482789d0-9e6a-403a-94d3-a50eab4ff82a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-482789d0-9e6a-403a-94d3-a50eab4ff82a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "df.head()"
      ],
      "id": "sJjScqV3FEIb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ntm8laX6FEIb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b655082d-ee9d-42da-eba8-602f37de03eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text         Customers continued to wait at drive-thru even...\n",
              "label                                                        0\n",
              "tokenized    [customers, continued, to, wait, at, drive-thr...\n",
              "Name: 42, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "df.iloc[42]"
      ],
      "id": "Ntm8laX6FEIb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Split the dataset into training, validation, and testing"
      ],
      "metadata": {
        "id": "TQVT6HUA9htQ"
      },
      "id": "TQVT6HUA9htQ"
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "PADDING_VALUE = 0\n",
        "UNK_VALUE     = 1\n",
        "rame\n",
        "\n",
        "\n",
        "def split_train_val_test(df, props=[.8, .1, .1]):\n",
        "    assert round(sum(props), 2) == 1 and len(props) >= 2\n",
        "    train_df, test_df, val_df = None, None, None\n",
        "    prev = 0\n",
        "    for i, prop in enumerate(props):\n",
        "      props[i] = prev + prop\n",
        "      prev = props[i]\n",
        "    train_df, val_df, test_df  = df.iloc[0:int(props[0] * len(df))], df.iloc[int(props[0] * len(df)):int(props[1] * len(df))], df.iloc[int(props[1] * len(df)):]\n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "def generate_vocab_map(df, cutoff=2):\n",
        "    vocab          = {\"\": PADDING_VALUE, \"UNK\": UNK_VALUE}\n",
        "    reversed_vocab = dict()\n",
        "    \n",
        "    freqMap = nltk.FreqDist(sum(df[\"tokenized\"].tolist(), []))\n",
        "    uniqId = 2\n",
        "    for word in freqMap.keys():\n",
        "      if freqMap[word] > cutoff:\n",
        "        vocab[word] = uniqId\n",
        "        uniqId += 1\n",
        "    for word in vocab.keys():\n",
        "      reversed_vocab[vocab[word]] = word\n",
        "    \n",
        "    return vocab, reversed_vocab"
      ],
      "metadata": {
        "id": "zeo9kX6i9pbH"
      },
      "id": "zeo9kX6i9pbH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcmX931OFEId"
      },
      "outputs": [],
      "source": [
        "df                         = df.sample(frac=1)\n",
        "train_df, val_df, test_df  = split_train_val_test(df, props=[.8, .1, .1])\n",
        "train_vocab, reverse_vocab = generate_vocab_map(train_df)"
      ],
      "id": "rcmX931OFEId"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAACzA8YFEId",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10075da9-3502-4c56-931a-abbb4a7d2a72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8, 0.1, 0.1)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "(len(train_df) / len(df)), (len(val_df) / len(df)), (len(test_df) / len(df))"
      ],
      "id": "CAACzA8YFEId"
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(df[\"tokenized\"][0]))\n",
        "print(torch.zeros([1], dtype=torch.int32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tnewg58Op1h",
        "outputId": "2a68d83a-596e-4346-a46f-a6f6d0d9529d"
      },
      "id": "7tnewg58Op1h",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "tensor([0], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Building a Dataset Class"
      ],
      "metadata": {
        "id": "5fCFfEHv1hnI"
      },
      "id": "5fCFfEHv1hnI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-qTQQa2FEIe"
      },
      "source": [
        "PyTorch has custom Dataset Classes that have very useful extentions, we want to turn our current pandas DataFrame into a subclass of Dataset so that we can iterate and sample through it for minibatch updates. **In the following cell, fill out the HeadlineDataset class.** Refer to PyTorch documentation on [Dataset Classes](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) \n",
        "for help."
      ],
      "id": "8-qTQQa2FEIe"
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class HeadlineDataset(Dataset):\n",
        "    \n",
        "    \n",
        "    def __init__(self, vocab, df, max_length=50):\n",
        "        self.vocab = vocab\n",
        "        self.df = df \n",
        "        self.df.reset_index(inplace = True)\n",
        "        self.max_length = max_length\n",
        "        return \n",
        "    def __len__(self):\n",
        "\n",
        "        df_len = None  \n",
        "        df_len = len(self.df)\n",
        "        return df_len\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        tokenized_word_tensor = None\n",
        "        curr_label            = None\n",
        "        l = self.df[\"tokenized\"][index]\n",
        "        tokenized_word_tensor = torch.empty([len(l)], dtype=torch.long)\n",
        "        for i, word in enumerate(l):\n",
        "          if word in self.vocab.keys():\n",
        "            tokenized_word_tensor[i] = self.vocab[word]\n",
        "          else:\n",
        "            tokenized_word_tensor[i] = self.vocab[\"UNK\"]\n",
        "        curr_label = self.df[\"label\"][index]\n",
        "        return tokenized_word_tensor, curr_label\n"
      ],
      "metadata": {
        "id": "tqt9q92J1QKK"
      },
      "id": "tqt9q92J1QKK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuLtIOAZFEIe"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import RandomSampler\n",
        "\n",
        "train_dataset = HeadlineDataset(train_vocab, train_df)\n",
        "val_dataset   = HeadlineDataset(train_vocab, val_df)\n",
        "test_dataset  = HeadlineDataset(train_vocab, test_df)\n",
        "\n",
        " \n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "val_sampler   = RandomSampler(val_dataset)\n",
        "test_sampler  = RandomSampler(test_dataset)"
      ],
      "id": "KuLtIOAZFEIe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Finishing DataLoader"
      ],
      "metadata": {
        "id": "n9iBiSKF1yXA"
      },
      "id": "n9iBiSKF1yXA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfXSbxoFFEIe"
      },
      "source": [
        "We can now use PyTorch DataLoaders to batch our data for us. **In the following cell fill out collate_fn.** Refer to PyTorch documentation on [DataLoaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) for help."
      ],
      "id": "lfXSbxoFFEIe"
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_fn(batch, padding_value=PADDING_VALUE):\n",
        "    padded_tokens, y_labels = None, None\n",
        "    maxlen = max(batch, key=len)\n",
        "    padded_tokens = pad_sequence([x[0] for x in batch], batch_first = True, padding_value = PADDING_VALUE)\n",
        "    y_labels = torch.Tensor([x[1] for x in batch])\n",
        "    return padded_tokens, y_labels"
      ],
      "metadata": {
        "id": "Zp1aQAvn1_mz"
      },
      "id": "Zp1aQAvn1_mz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OayoJRTeFEIf"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, collate_fn=collate_fn)\n",
        "val_iterator   = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=val_sampler, collate_fn=collate_fn)\n",
        "test_iterator  = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=test_sampler, collate_fn=collate_fn)"
      ],
      "id": "OayoJRTeFEIf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pidbg12AFEIf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa54befc-e960-48f9-8f65-79654af2a868"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: torch.Size([16, 23])\n",
            "y: torch.Size([16])\n"
          ]
        }
      ],
      "source": [
        "for x, y in test_iterator:\n",
        "    print(f'x: {x.shape}')\n",
        "    print(f'y: {y.shape}')\n",
        "    break\n",
        "test_iterator = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=test_sampler, collate_fn=collate_fn)"
      ],
      "id": "pidbg12AFEIf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWLK7T1uFEIg"
      },
      "source": [
        "### Create NBOW Model\n",
        "Architecture Reference: Section 2.1 in (https://www.aclweb.org/anthology/P15-1162.pdf). "
      ],
      "id": "BWLK7T1uFEIg"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class NBOW(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super().__init__()\n",
        "        self.embedLayer = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linearLayer = nn.Linear(embedding_dim, 1)\n",
        "        self.sigmoidLayer = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        EmbedOutput = self.embedLayer(x)\n",
        "        LinearOutput = self.linearLayer(torch.mean(EmbedOutput, dim=1))\n",
        "        return torch.squeeze(self.sigmoidLayer(LinearOutput))\n",
        "\n"
      ],
      "metadata": {
        "id": "jzGx2q0jLqyU"
      },
      "execution_count": null,
      "outputs": [],
      "id": "jzGx2q0jLqyU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HQWUu-ZFEIg"
      },
      "outputs": [],
      "source": [
        "model = NBOW(vocab_size    = len(train_vocab.keys()),\n",
        "             embedding_dim = 300).to(device)"
      ],
      "id": "_HQWUu-ZFEIg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss function and Optimizer"
      ],
      "metadata": {
        "id": "C4CZnj1f-da-"
      },
      "id": "C4CZnj1f-da-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w98UvlXxFEIh"
      },
      "outputs": [],
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "criterion, optimizer = None, None\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = Adam(model.parameters(), lr = .001)\n",
        "\n"
      ],
      "id": "w98UvlXxFEIh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVLeTa8wFEIh"
      },
      "source": [
        "### Part 3: Training and Evaluation\n"
      ],
      "id": "bVLeTa8wFEIh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vganx5fCFEIh"
      },
      "outputs": [],
      "source": [
        "def train_loop(model, criterion, optim, iterator):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for x, y in tqdm(iterator):\n",
        "        output = model(x.to(device))\n",
        "        loss = criterion(output, y.to(device))\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss\n",
        "\n",
        "def val_loop(model, iterator):\n",
        "    true, pred = [], []\n",
        "    for x, y in tqdm(iterator):\n",
        "      predictedVals = model(x.to(device))\n",
        "      trueVals = y.to(device)\n",
        "      true = [x == 1 for x in trueVals]\n",
        "      pred = [x >= .5 for x in predictedVals]\n",
        "    return true, pred"
      ],
      "id": "vganx5fCFEIh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define and Use evaluation metrics\n",
        "\n",
        "For the sake of learning, I chose to implement my own evaluation metrics."
      ],
      "metadata": {
        "id": "JNXJevTu-tDZ"
      },
      "id": "JNXJevTu-tDZ"
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(true, pred):\n",
        "    acc = None\n",
        "    ## YOUR CODE STARTS HERE (~2-5 lines of code) ##\n",
        "    arr = [x[0] == x[1] for x in zip(true, pred)]\n",
        "    acc = sum(arr) / len(arr)\n",
        "    ## YOUR CODE ENDS HERE ##\n",
        "    return acc\n",
        "\n",
        "\n",
        "def binary_f1(true, pred, selected_class=True):\n",
        "    f1 = None\n",
        "    ## YOUR CODE STARTS HERE (~10-15 lines of code) ##\n",
        "    tup = zip(true, pred)\n",
        "    tp = 0\n",
        "    tn = 0 \n",
        "    fp = 0\n",
        "    fn = 0\n",
        "    for t, p in tup:\n",
        "      if t == p:\n",
        "        if p == True:\n",
        "          tp += 1\n",
        "        else:\n",
        "          tn += 1\n",
        "      else:\n",
        "        if t == True and p == False:\n",
        "          fn += 1\n",
        "        else:\n",
        "          fp += 1\n",
        "\n",
        "    if selected_class:\n",
        "      tprecision = 0\n",
        "      if tp + fp == 0:\n",
        "        tprecision = 0\n",
        "      else:\n",
        "        tprecision = tp / (tp + fp)\n",
        "      trecall = 0\n",
        "      if tp + fn == 0:\n",
        "        trecall = 0\n",
        "      else:\n",
        "        trecall = tp / (tp + fn)\n",
        "      if tprecision + trecall == 0:\n",
        "        return 0\n",
        "      f1 = 2 * (tprecision * trecall) / (tprecision + trecall)\n",
        "    else:\n",
        "      fprecision = 0\n",
        "      if tn + fn == 0:\n",
        "        fprecision = 0\n",
        "      else:\n",
        "        fprecision = tn / (tn + fn)\n",
        "      frecall = 0\n",
        "      if tn + fp == 0:\n",
        "        frecall = 0\n",
        "      else:\n",
        "        frecall = tn / (tn + fp)\n",
        "      if fprecision + frecall == 0:\n",
        "        return 0\n",
        "      f1 = 2 * (fprecision * frecall) / (fprecision + frecall)\n",
        "    ## YOUR CODE ENDS HERE ##\n",
        "    return f1\n",
        "\n",
        "\n",
        "def binary_macro_f1(true, pred):\n",
        "    averaged_macro_f1 = None\n",
        "    averaged_macro_f1 = (binary_f1(true, pred, selected_class=True) + binary_f1(true, pred, selected_class=False)) / 2\n",
        "    return averaged_macro_f1"
      ],
      "metadata": {
        "id": "gMQDg9Vy-wY0"
      },
      "id": "gMQDg9Vy-wY0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yw79JFieFEIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4509df91-f16f-459f-c40f-ac1e3d6c311d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [00:00<00:00, 553.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Binary Macro F1: 0.375\n",
            "Accuracy: 0.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "true, pred = val_loop(model, val_iterator)\n",
        "print()\n",
        "print(f'Binary Macro F1: {binary_macro_f1(true, pred)}')\n",
        "print(f'Accuracy: {accuracy(true, pred)}')"
      ],
      "id": "Yw79JFieFEIi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2to0kWVFEIi"
      },
      "source": [
        "### Part 4: Training the model "
      ],
      "id": "Q2to0kWVFEIi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-iuqkKCFEIj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fd0f7d4-fbd4-406a-8656-05613cc885c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:03<00:00, 385.75it/s]\n",
            "100%|██████████| 150/150 [00:00<00:00, 570.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 0\n",
            "TRAIN LOSS: 621.4540008604527\n",
            "VAL F-1: 0.5897435897435898\n",
            "VAL ACC: 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:03<00:00, 384.94it/s]\n",
            "100%|██████████| 150/150 [00:00<00:00, 558.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 1\n",
            "TRAIN LOSS: 404.4328829944134\n",
            "VAL F-1: 0.8333333333333333\n",
            "VAL ACC: 0.875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:03<00:00, 385.53it/s]\n",
            "100%|██████████| 150/150 [00:00<00:00, 550.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 2\n",
            "TRAIN LOSS: 317.68711391836405\n",
            "VAL F-1: 0.746031746031746\n",
            "VAL ACC: 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:03<00:00, 382.98it/s]\n",
            "100%|██████████| 150/150 [00:00<00:00, 555.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 3\n",
            "TRAIN LOSS: 267.90556765161455\n",
            "VAL F-1: 0.9352226720647774\n",
            "VAL ACC: 0.9375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:03<00:00, 385.54it/s]\n",
            "100%|██████████| 150/150 [00:00<00:00, 552.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 4\n",
            "TRAIN LOSS: 229.62556424643844\n",
            "VAL F-1: 0.9372549019607843\n",
            "VAL ACC: 0.9375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:03<00:00, 386.34it/s]\n",
            "100%|██████████| 150/150 [00:00<00:00, 559.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 5\n",
            "TRAIN LOSS: 201.79788933508098\n",
            "VAL F-1: 0.8117647058823529\n",
            "VAL ACC: 0.8125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:03<00:00, 386.44it/s]\n",
            "100%|██████████| 150/150 [00:00<00:00, 558.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 6\n",
            "TRAIN LOSS: 179.83632330223918\n",
            "VAL F-1: 1.0\n",
            "VAL ACC: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:03<00:00, 388.64it/s]\n",
            "100%|██████████| 150/150 [00:00<00:00, 556.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 7\n",
            "TRAIN LOSS: 159.9260141660925\n",
            "VAL F-1: 0.9352226720647774\n",
            "VAL ACC: 0.9375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:03<00:00, 387.05it/s]\n",
            "100%|██████████| 150/150 [00:00<00:00, 552.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 8\n",
            "TRAIN LOSS: 144.3743618351873\n",
            "VAL F-1: 0.8545454545454546\n",
            "VAL ACC: 0.875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:03<00:00, 387.43it/s]\n",
            "100%|██████████| 150/150 [00:00<00:00, 562.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 9\n",
            "TRAIN LOSS: 131.1241482088808\n",
            "VAL F-1: 0.7090909090909091\n",
            "VAL ACC: 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "TOTAL_EPOCHS = 10\n",
        "for epoch in range(TOTAL_EPOCHS):\n",
        "    train_loss = train_loop(model, criterion, optimizer, train_iterator)\n",
        "    true, pred = val_loop(model, val_iterator)\n",
        "    print(f\"EPOCH: {epoch}\")\n",
        "    print(f\"TRAIN LOSS: {train_loss}\")\n",
        "    print(f\"VAL F-1: {binary_macro_f1(true, pred)}\")\n",
        "    print(f\"VAL ACC: {accuracy(true, pred)}\")"
      ],
      "id": "N-iuqkKCFEIj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l91F4ooFEIj"
      },
      "source": [
        "We can also look at the models performance on the held-out test set, using the same val_loop we wrote earlier."
      ],
      "id": "_l91F4ooFEIj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vs8Fy_ncFEIo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f938c30f-4ece-486f-a5ed-21e0a7cfa953"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [00:00<00:00, 559.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TEST F-1: 0.8666666666666667\n",
            "TEST ACC: 0.875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "true, pred = val_loop(model, test_iterator)\n",
        "print()\n",
        "print(f\"TEST F-1: {binary_macro_f1(true, pred)}\")\n",
        "print(f\"TEST ACC: {accuracy(true, pred)}\")"
      ],
      "id": "vs8Fy_ncFEIo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 6: LSTM Model "
      ],
      "metadata": {
        "id": "Ie9VqRbg78Ty"
      },
      "id": "Ie9VqRbg78Ty"
    },
    {
      "cell_type": "code",
      "source": [
        "class RecurrentModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, \\\n",
        "                 num_layers=1, bidirectional=True):\n",
        "        super().__init__()\n",
        "        mult = 1\n",
        "        if(bidirectional):\n",
        "          mult = 2\n",
        "        self.embedLayer = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.LSTMLayer = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=num_layers, bidirectional=bidirectional, batch_first=True)\n",
        "        self.linearLayer = nn.Linear(mult * embedding_dim, 1)\n",
        "        self.sigmoidLayer = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        EmbedOutput = self.embedLayer(x)\n",
        "        LSTMOutput, (hidden, cell) = self.LSTMLayer(EmbedOutput)\n",
        "        LinearOutput = self.linearLayer(LSTMOutput[:, -1, :])\n",
        "        return torch.squeeze(self.sigmoidLayer(LinearOutput))\n",
        "    "
      ],
      "metadata": {
        "id": "YN8zvhLJ-MVJ"
      },
      "id": "YN8zvhLJ-MVJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, collate_fn=collate_fn)\n",
        "val_iterator   = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=val_sampler, collate_fn=collate_fn)\n",
        "test_iterator  = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=test_sampler, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "6-uftfXEAqOi"
      },
      "id": "6-uftfXEAqOi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model = RecurrentModel(vocab_size    = len(train_vocab.keys()),\n",
        "                            embedding_dim = 300,\n",
        "                            hidden_dim    = 300,\n",
        "                            num_layers    = 5,\n",
        "                            bidirectional = False).to(device)"
      ],
      "metadata": {
        "id": "LNWcLJpsBRzg"
      },
      "id": "LNWcLJpsBRzg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.adagrad import Adagrad\n",
        "from torch.optim import Adam\n",
        "\n",
        "lstm_criterion, lstm_optimizer = None, None\n",
        "lstm_criterion = nn.BCELoss()\n",
        "lstm_optimizer = Adam(lstm_model.parameters(), lr = .001)\n"
      ],
      "metadata": {
        "id": "OdTxe0bFBqnP"
      },
      "id": "OdTxe0bFBqnP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and Evaluation\n",
        "\n"
      ],
      "metadata": {
        "id": "NFvV7H7OBzWl"
      },
      "id": "NFvV7H7OBzWl"
    },
    {
      "cell_type": "code",
      "source": [
        "true, pred = val_loop(lstm_model, val_iterator)\n",
        "print()\n",
        "print(f'Binary Macro F1: {binary_macro_f1(true, pred)}')\n",
        "print(f'Accuracy: {accuracy(true, pred)}')"
      ],
      "metadata": {
        "id": "SdkEpedxDopv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3021ebfe-b2b8-4aa9-9bab-64e76d4930d9"
      },
      "id": "SdkEpedxDopv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [00:00<00:00, 218.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Binary Macro F1: 0.36\n",
            "Accuracy: 0.5625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TOTAL_EPOCHS = 10\n",
        "for epoch in range(TOTAL_EPOCHS):\n",
        "    train_loss = train_loop(lstm_model, lstm_criterion, lstm_optimizer, train_iterator)\n",
        "    true, pred = val_loop(lstm_model, val_iterator)\n",
        "    print(f\"EPOCH: {epoch}\")\n",
        "    print(f\"TRAIN LOSS: {train_loss}\")\n",
        "    print(f\"VAL F-1: {binary_macro_f1(true, pred)}\")\n",
        "    print(f\"VAL ACC: {accuracy(true, pred)}\")"
      ],
      "metadata": {
        "id": "6p2dF9X4DyIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91a95a38-d989-4a8f-d201-630895816d7a"
      },
      "id": "6p2dF9X4DyIR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:12<00:00, 94.15it/s]\n",
            "100%|██████████| 150/150 [00:00<00:00, 219.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 0\n",
            "TRAIN LOSS: 711.4798891246319\n",
            "VAL F-1: 0.805668016194332\n",
            "VAL ACC: 0.8125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:12<00:00, 94.81it/s]\n",
            "100%|██████████| 150/150 [00:00<00:00, 221.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 1\n",
            "TRAIN LOSS: 601.4297215938568\n",
            "VAL F-1: 0.746031746031746\n",
            "VAL ACC: 0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:12<00:00, 94.94it/s]\n",
            "100%|██████████| 150/150 [00:00<00:00, 217.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 2\n",
            "TRAIN LOSS: 399.8543336354196\n",
            "VAL F-1: 0.8666666666666667\n",
            "VAL ACC: 0.875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:12<00:00, 94.85it/s]\n",
            "100%|██████████| 150/150 [00:00<00:00, 223.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 3\n",
            "TRAIN LOSS: 289.0646998193115\n",
            "VAL F-1: 0.9352226720647774\n",
            "VAL ACC: 0.9375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:12<00:00, 94.63it/s]\n",
            "100%|██████████| 150/150 [00:00<00:00, 219.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 4\n",
            "TRAIN LOSS: 221.1596870906651\n",
            "VAL F-1: 0.8117647058823529\n",
            "VAL ACC: 0.8125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:12<00:00, 94.53it/s]\n",
            "100%|██████████| 150/150 [00:00<00:00, 218.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 5\n",
            "TRAIN LOSS: 162.88612027280033\n",
            "VAL F-1: 0.7681159420289854\n",
            "VAL ACC: 0.8125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:12<00:00, 94.00it/s]\n",
            "100%|██████████| 150/150 [00:00<00:00, 221.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 6\n",
            "TRAIN LOSS: 110.52352964691818\n",
            "VAL F-1: 1.0\n",
            "VAL ACC: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:12<00:00, 93.93it/s]\n",
            "100%|██████████| 1200/1200 [00:12<00:00, 94.34it/s]\n",
            "100%|██████████| 150/150 [00:00<00:00, 218.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 8\n",
            "TRAIN LOSS: 65.77736117457971\n",
            "VAL F-1: 0.8666666666666667\n",
            "VAL ACC: 0.875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [00:12<00:00, 94.07it/s]\n",
            "100%|██████████| 150/150 [00:00<00:00, 218.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 9\n",
            "TRAIN LOSS: 61.73469458904583\n",
            "VAL F-1: 0.8545454545454546\n",
            "VAL ACC: 0.875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true, pred = val_loop(lstm_model, test_iterator)\n",
        "print()\n",
        "print(f\"TEST F-1: {binary_macro_f1(true, pred)}\")\n",
        "print(f\"TEST ACC: {accuracy(true, pred)}\")"
      ],
      "metadata": {
        "id": "OR8Dl5DLEQwd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be7e5537-1db2-4a27-db1b-7c15a1377c53"
      },
      "id": "OR8Dl5DLEQwd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 150/150 [00:00<00:00, 214.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TEST F-1: 0.873015873015873\n",
            "TEST ACC: 0.875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}